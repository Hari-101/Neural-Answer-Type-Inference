{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Randomness_Check_203170005_CS728_Assignment3_Q2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Hari-101/Neural-Answer-Type-Inference.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AgPk04kgyG_",
        "outputId": "f727924c-3759-4a04-9b03-d3b57d1df293"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Neural-Answer-Type-Inference' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "AewH3SUh_14r"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    #random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(100)"
      ],
      "metadata": {
        "id": "X4NOdvu9HUBE"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "root = os.getcwd()\n",
        "root"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dGIOqTUnhVDX",
        "outputId": "0c529e1f-a31d-4cfc-c308-db90567b386b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_datasource = root + '/Neural-Answer-Type-Inference/Dataset/AnswerTypeInference_Train_Data.txt'"
      ],
      "metadata": {
        "id": "dBYf6E81ODbZ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "VK2JAqpKBSYg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "bea7d540-6d7d-4ee2-ba18-fe89776e23f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               question coarse_label  \\\n",
              "0     How did serfdom develop in and then leave Russia          DESC   \n",
              "1       What films featured the character Popeye Doyle          ENTY   \n",
              "2     How can I find a list of celebrities ' real na...         DESC   \n",
              "3     What fowl grabs the spotlight after the Chines...         ENTY   \n",
              "4                        What is the full form of .com          ABBR   \n",
              "...                                                 ...          ...   \n",
              "5447             What 's the shape of a camel 's spine          ENTY   \n",
              "5448            What type of currency is used in China          ENTY   \n",
              "5449                     What is the temperature today           NUM   \n",
              "5450               What is the temperature for cooking           NUM   \n",
              "5451                 What currency is used in Australia         ENTY   \n",
              "\n",
              "     fine_label  \n",
              "0        manner  \n",
              "1        cremat  \n",
              "2        manner  \n",
              "3        animal  \n",
              "4           exp  \n",
              "...         ...  \n",
              "5447      other  \n",
              "5448   currency  \n",
              "5449       temp  \n",
              "5450       temp  \n",
              "5451   currency  \n",
              "\n",
              "[5452 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdb76837-772f-48b7-b955-6e8a4629b2b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>coarse_label</th>\n",
              "      <th>fine_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How did serfdom develop in and then leave Russia</td>\n",
              "      <td>DESC</td>\n",
              "      <td>manner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What films featured the character Popeye Doyle</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>cremat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I find a list of celebrities ' real na...</td>\n",
              "      <td>DESC</td>\n",
              "      <td>manner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>animal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the full form of .com</td>\n",
              "      <td>ABBR</td>\n",
              "      <td>exp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5447</th>\n",
              "      <td>What 's the shape of a camel 's spine</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>What type of currency is used in China</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>currency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5449</th>\n",
              "      <td>What is the temperature today</td>\n",
              "      <td>NUM</td>\n",
              "      <td>temp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5450</th>\n",
              "      <td>What is the temperature for cooking</td>\n",
              "      <td>NUM</td>\n",
              "      <td>temp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5451</th>\n",
              "      <td>What currency is used in Australia</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>currency</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5452 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdb76837-772f-48b7-b955-6e8a4629b2b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdb76837-772f-48b7-b955-6e8a4629b2b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdb76837-772f-48b7-b955-6e8a4629b2b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "def get_data(path):\n",
        "  coarse_label = []\n",
        "  fine_label = []\n",
        "  question = []\n",
        "  with open(path) as f:\n",
        "      for line in f:\n",
        "          label, ques = line.split(maxsplit=1)\n",
        "          coarse_label.append(label.split(':')[0])\n",
        "          fine_label.append(label.split(':')[1])\n",
        "          question.append(ques[:-2])\n",
        "  return question, coarse_label, fine_label\n",
        "\n",
        "question, coarse_label, fine_label = get_data(path_to_datasource)\n",
        "\n",
        "df = pd.DataFrame(zip(question, coarse_label, fine_label), columns=['question', 'coarse_label', 'fine_label'])\n",
        "df    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['fine_label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Nqg--_A9as",
        "outputId": "fa307666-a78e-4027-a73b-d4f28aa71690"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['fine_label'] == 'instru']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "-IfLgNVQCRuz",
        "outputId": "950c7925-3662-4c81-cc56-6179688a1e69"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               question coarse_label  \\\n",
              "256   What instrument is Ray Charles best known for ...         ENTY   \n",
              "457   What musical instrument did Prewitt play in Ja...         ENTY   \n",
              "1012  What musical instrument did Sherlock Holmes play          ENTY   \n",
              "1247                Ray Charles plays which instrument          ENTY   \n",
              "1361  What musical instrument did Prewitt play in Ja...         ENTY   \n",
              "1834         What kind of guitar did Jimi Hendrix play          ENTY   \n",
              "1853        Musician Ray Charles plays what instrument          ENTY   \n",
              "2312  What do West Indian steel bands use as instrum...         ENTY   \n",
              "3190  Ray Charles is best known for playing what ins...         ENTY   \n",
              "3897            What instrument does Benny Carter play          ENTY   \n",
              "\n",
              "     fine_label  \n",
              "256      instru  \n",
              "457      instru  \n",
              "1012     instru  \n",
              "1247     instru  \n",
              "1361     instru  \n",
              "1834     instru  \n",
              "1853     instru  \n",
              "2312     instru  \n",
              "3190     instru  \n",
              "3897     instru  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cc1c065-01d2-4f38-b78b-46f1202aa545\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>coarse_label</th>\n",
              "      <th>fine_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>What instrument is Ray Charles best known for ...</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>instru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>What musical instrument did Prewitt play in Ja...</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>instru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1012</th>\n",
              "      <td>What musical instrument did Sherlock Holmes play</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>instru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1247</th>\n",
              "      <td>Ray Charles plays which instrument</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>instru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1361</th>\n",
              "      <td>What musical instrument did Prewitt play in Ja...</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>instru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1834</th>\n",
              "      <td>What kind of guitar did Jimi Hendrix play</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>instru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1853</th>\n",
              "      <td>Musician Ray Charles plays what instrument</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>instru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2312</th>\n",
              "      <td>What do West Indian steel bands use as instrum...</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>instru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3190</th>\n",
              "      <td>Ray Charles is best known for playing what ins...</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>instru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3897</th>\n",
              "      <td>What instrument does Benny Carter play</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>instru</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cc1c065-01d2-4f38-b78b-46f1202aa545')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5cc1c065-01d2-4f38-b78b-46f1202aa545 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5cc1c065-01d2-4f38-b78b-46f1202aa545');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting the device to train/ run the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SWNFc3A-mNF",
        "outputId": "709f768b-320d-4214-9673-179c78480310"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialising BERT tokenizer as well as bert-base-uncased model for accessing pre-trained BERT embeddings\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizerFast, BertModel\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "emb_gen_model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True,\n",
        "                                  )\n",
        "\n",
        "emb_gen_model.to(device)"
      ],
      "metadata": {
        "id": "wdj1PMo4Cc0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef70aa7a-9c4c-4876-dda2-56f0e9a2f88f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cls_list(question):\n",
        "  cls_list = []\n",
        "\n",
        "  for q in question:\n",
        "    tokenized_text = tokenizer(q, return_tensors='pt', padding=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = emb_gen_model(**tokenized_text)\n",
        "      #For each sample, extract out the last layer embedding of the [CLS] token\n",
        "      cls_list.append(outputs[0][0][0].unsqueeze(dim=0))    #and correcting embedding size\n",
        "  return cls_list\n",
        "\n",
        "cls_list = get_cls_list(question)"
      ],
      "metadata": {
        "id": "-qpuPssp2vIM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train-validation split cls_list and targets\n",
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(fine_label)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "rand_seed = 42\n",
        "\n",
        "cls_list_train, cls_list_val, fine_label_train, fine_label_val = \\\n",
        "train_test_split(cls_list, fine_label, test_size= 0.1, \\\n",
        "                 random_state = rand_seed, stratify = fine_label)"
      ],
      "metadata": {
        "id": "PGHhun_bNBd_"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training tensors\n",
        "train_input_ids = torch.cat(cls_list_train, dim=0)\n",
        "train_target = torch.tensor(le.transform(fine_label_train))\n",
        "\n",
        "#Validation tensors\n",
        "val_input_ids = torch.cat(cls_list_val, dim=0)\n",
        "val_target = torch.tensor(le.transform(fine_label_val))"
      ],
      "metadata": {
        "id": "qu_tgRWlutNy"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids.size()\n",
        "torch.max(train_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLnxmq-3NZ__",
        "outputId": "9351e7bf-22f8-4628-e48f-83aaabb25dee"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(46)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_dataset = TensorDataset(train_input_ids, train_target)\n",
        "val_dataset = TensorDataset(val_input_ids, val_target)\n",
        "\n",
        "train_batch_size = 512\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                          batch_size=train_batch_size,\n",
        "                                          shuffle=True)"
      ],
      "metadata": {
        "id": "Sq3M1rWE6BxE"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 1000\n",
        "param = {\n",
        "    'i_d' : train_dataset[0][0].size(-1),\n",
        "    'h_d' : hidden_dim,\n",
        "    'o_d' : torch.max(train_target) + 1\n",
        "}"
      ],
      "metadata": {
        "id": "aNSV_QSgOea9"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the neural network model\n",
        "import torch.nn as nn\n",
        "\n",
        "class ATI_Net(nn.Module):\n",
        "    def __init__(self, param: dict):\n",
        "      super().__init__()\n",
        "      self.param = param\n",
        "      self.model = nn.Sequential(\n",
        "          nn.Linear(self.param['i_d'], self.param['h_d']),  \n",
        "          nn.ReLU(),\n",
        "          nn.Linear(self.param['h_d'], self.param['o_d']),\n",
        "      )\n",
        "      \n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "\n",
        "#Initialise the model\n",
        "model = ATI_Net(param)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fArhiLPdN-ev",
        "outputId": "d3463913-9d3f-4fc9-b3a8-fc147239bb95"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ATI_Net(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=1000, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1000, out_features=47, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper-parameters\n",
        "#Batch size\n",
        "#training batch size set at dataloader initialisation\n",
        "\n",
        "#Optimiser\n",
        "import torch.optim as opt\n",
        "\n",
        "learn_rate = 1e-3  #learning rate\n",
        "optim = opt.Adam(model.parameters(), lr=learn_rate) #optimiser\n",
        "\n",
        "#Loss function\n",
        "criterion=nn.CrossEntropyLoss(reduction = 'sum')  #Loss function"
      ],
      "metadata": {
        "id": "YV6Tr3Y1PlSq"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  for _, data in enumerate(train_data_loader):\n",
        "\n",
        "    X, label = data\n",
        "    label=label.to(device)\n",
        "    \n",
        "    output=model(X)\n",
        "    loss=criterion(output, label)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    break"
      ],
      "metadata": {
        "id": "Q5M64zazSNG4"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mctm3pUOWSgr",
        "outputId": "e81a2872-1960-4335-ab28-b27a0b353cf9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhdncvziTytN",
        "outputId": "eddafc77-ebc6-4302-f5f8-f9b008016e06"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 47])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns the evaluation dataset cross-entropy loss and accuracy.\n",
        "\n",
        "def eval_model(model, d_set): \n",
        "\n",
        "  preds = []\n",
        "  correct = 0\n",
        "  eval_batch_size = 512\n",
        "  eval_loss = 0\n",
        "  eval_data_loader = torch.utils.data.DataLoader(d_set,\n",
        "                                          batch_size=eval_batch_size, shuffle=False)\n",
        "  \n",
        "  model.eval()\n",
        "  for X, label in eval_data_loader:\n",
        "    X=X.to(device)\n",
        "    label=label.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      output=model(X)\n",
        "      loss=criterion(output, label)\n",
        "      correct += torch.sum(torch.max(output, dim=-1).indices == label.flatten())\n",
        "      preds.append(torch.max(output, dim=-1).indices.flatten())\n",
        "      eval_loss += loss.item()\n",
        "\n",
        "  pred_labels = torch.cat(preds, dim=-1)\n",
        "  return (correct/len(d_set)), (eval_loss/len(d_set)), le.inverse_transform(pred_labels.to('cpu'))\n"
      ],
      "metadata": {
        "id": "ISq42vL-Tw_b"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_eval_1_epoch(model, epoch):\n",
        "\n",
        "  # Reset the total loss for this epoch.\n",
        "  total_train_loss = 0\n",
        "\n",
        "  model.train()\n",
        "  for _, data in enumerate(train_data_loader):\n",
        "\n",
        "    X, label = data\n",
        "    X = X.to(device)\n",
        "    label = label.to(device)\n",
        "    \n",
        "    output=model(X)\n",
        "    loss=criterion(output, label)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    total_train_loss += loss.item()\n",
        "    optim.step()\n",
        "  \n",
        "  _, eval_loss, _ = eval_model(model, val_dataset)\n",
        "\n",
        "  print(f\"For epoch {epoch}, training loss is {total_train_loss/len(train_dataset)} and evaluation loss is {eval_loss}.\")\n"
      ],
      "metadata": {
        "id": "gJ-tIoB1Qoar"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 25\n",
        "\n",
        "for epoch_i in range(num_epochs):\n",
        "\n",
        "  print(f\"Epoch number {epoch_i}\")\n",
        "  train_eval_1_epoch(model, epoch_i)\n"
      ],
      "metadata": {
        "id": "a-s5U7JoV4UQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4581021-a9f8-412a-8c2f-821d0c8e9def"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch number 0\n",
            "For epoch 0, training loss is 2.9447884759852414 and evaluation loss is 2.633495330810547.\n",
            "Epoch number 1\n",
            "For epoch 1, training loss is 2.413878710280619 and evaluation loss is 2.2703651176704156.\n",
            "Epoch number 2\n",
            "For epoch 2, training loss is 2.0387452565258104 and evaluation loss is 1.979385976826315.\n",
            "Epoch number 3\n",
            "For epoch 3, training loss is 1.745997948691255 and evaluation loss is 1.746841577383188.\n",
            "Epoch number 4\n",
            "For epoch 4, training loss is 1.5169201060503879 and evaluation loss is 1.5715846037253356.\n",
            "Epoch number 5\n",
            "For epoch 5, training loss is 1.341296003538397 and evaluation loss is 1.4221541855361435.\n",
            "Epoch number 6\n",
            "For epoch 6, training loss is 1.1905650322747336 and evaluation loss is 1.3213162474579863.\n",
            "Epoch number 7\n",
            "For epoch 7, training loss is 1.076750433790018 and evaluation loss is 1.261642078776936.\n",
            "Epoch number 8\n",
            "For epoch 8, training loss is 0.9859147132099088 and evaluation loss is 1.1615552028893552.\n",
            "Epoch number 9\n",
            "For epoch 9, training loss is 0.8973690861835316 and evaluation loss is 1.1273720150902158.\n",
            "Epoch number 10\n",
            "For epoch 10, training loss is 0.8304765703626618 and evaluation loss is 1.0600578182346219.\n",
            "Epoch number 11\n",
            "For epoch 11, training loss is 0.7621806067347381 and evaluation loss is 1.0197188967750186.\n",
            "Epoch number 12\n",
            "For epoch 12, training loss is 0.7068965334917544 and evaluation loss is 1.0343081156412761.\n",
            "Epoch number 13\n",
            "For epoch 13, training loss is 0.6707873307487404 and evaluation loss is 0.9828867929759043.\n",
            "Epoch number 14\n",
            "For epoch 14, training loss is 0.6330856932847295 and evaluation loss is 0.9620405832926432.\n",
            "Epoch number 15\n",
            "For epoch 15, training loss is 0.5863618909024823 and evaluation loss is 0.9218063144893437.\n",
            "Epoch number 16\n",
            "For epoch 16, training loss is 0.5483820371320672 and evaluation loss is 0.9222546182709299.\n",
            "Epoch number 17\n",
            "For epoch 17, training loss is 0.5122600326818006 and evaluation loss is 0.8822426359295409.\n",
            "Epoch number 18\n",
            "For epoch 18, training loss is 0.48407456420948203 and evaluation loss is 0.8853033016889523.\n",
            "Epoch number 19\n",
            "For epoch 19, training loss is 0.46603869108875773 and evaluation loss is 0.8790262941912417.\n",
            "Epoch number 20\n",
            "For epoch 20, training loss is 0.4489965240565602 and evaluation loss is 0.8937506763053028.\n",
            "Epoch number 21\n",
            "For epoch 21, training loss is 0.42340389116413973 and evaluation loss is 0.8604763506096361.\n",
            "Epoch number 22\n",
            "For epoch 22, training loss is 0.3944074410688522 and evaluation loss is 0.8673706124553751.\n",
            "Epoch number 23\n",
            "For epoch 23, training loss is 0.3737518179917209 and evaluation loss is 0.8466962597745679.\n",
            "Epoch number 24\n",
            "For epoch 24, training loss is 0.3550672099583498 and evaluation loss is 0.8425401680635445.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "print(len(val_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI363qti9-Sg",
        "outputId": "1ae7df3b-4620-4179-d52d-a68b4c8b1554"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4906\n",
            "546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_eval = train_dataset + val_dataset\n",
        "print(len(train_eval))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSwoxksu99jQ",
        "outputId": "19786460-9f8e-40fa-bcbd-9fe3c9e88040"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc, _, _ = eval_model(model, train_dataset)\n",
        "(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiHe-5bIXxlY",
        "outputId": "03e66238-dab0-4a8c-b7a4-620134906b78"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9130, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc, _, _ = eval_model(model, train_eval)\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NZMP4d4-JH7",
        "outputId": "92026314-4c22-468b-be38-8c5d08bd4b22"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8986, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_test_data = root + '/Neural-Answer-Type-Inference/Dataset/AnswerTypeInference_Test_Data.txt'\n",
        "question_test, coarse_label_test, fine_label_test = get_data(path_to_test_data)"
      ],
      "metadata": {
        "id": "eAAe65uyxKQV"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls_list_test = get_cls_list(question_test)"
      ],
      "metadata": {
        "id": "XDmZ7HJAxI2H"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test dataset\n",
        "test_input_ids = torch.cat(cls_list_test, dim=0)\n",
        "test_target = torch.tensor(le.transform(fine_label_test))\n",
        "\n",
        "test_dataset = TensorDataset(test_input_ids, test_target)"
      ],
      "metadata": {
        "id": "3Gl17-koztza"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc, _, y_preds = eval_model(model, test_dataset)\n",
        "print(\"Accuracy of model on test dataset is\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xayh4S_0-fb9",
        "outputId": "8a1cf740-34dc-430f-cf65-940dc8f36354"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model on test dataset is tensor(0.8000, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = list(zip(fine_label, coarse_label))\n",
        "mapping = set(lst)\n",
        "mapping.remove(('other', 'LOC'))\n",
        "mapping.remove(('other', 'NUM'))\n",
        "lookup = dict(list(mapping))\n",
        "\n",
        "y_coarse = []\n",
        "for pred in y_preds:\n",
        "  y_coarse.append(lookup[pred])"
      ],
      "metadata": {
        "id": "qTqfW7GuffRJ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(zip(y_coarse, y_preds, question_test))\n",
        "test_df.to_csv(\"test_predictions.csv\",index = False, header = False)"
      ],
      "metadata": {
        "id": "RX-Y4gWxcF-d"
      },
      "execution_count": 76,
      "outputs": []
    }
  ]
}